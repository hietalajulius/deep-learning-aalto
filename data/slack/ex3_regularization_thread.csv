0
" “Maximum number of epochs with unsuccessful updates” is the same as waiting “for patience epochs” in a row.

Practically this is often true as after achieving minimum error the model usually starts to overfit. However as I understand it, the former description does not state anything about the successive epochs all needing to be uncessful in a row. After reaching the minimum loss there can be fluctuations in between successive epochs as well, and one can see for example sequence of 100  updates that are above the achieved minimum loss but still under the tolerance without any unsuccessful updates. Or there can be some that are over the tolerance as well. These need to be counted. Am I understanding it correctly? If I am, then this is not the same as ""for patience epochs” in a row.

In both cases you need to check at most patience number of epochs to make a decision  regarding stopping.

At most patience number of epochs? Shouldn't this be at least? Or do you mean to say at most patience number of **unsuccessful updates** instead of just epochs? (edited)"
"@Dmitry Sergeev (TA), oh sorry I didn’t see the previous post, I’ve followed the comments on the code that just mention “Maximum number of epochs with unsuccessful updates”. There is no mention to consecutive there. (edited)"
"@Pedro Neto Alright, but do you reset the patience to its initial value if you find new local minimum as discussed in a few posts above? In your implementation, I believe, the counter can only go down. And since you rewrite the variable in the attribute, I think you can’t easily set it back"
Abnormalities are actually really great point didn't think about it.
Always Tuesday 6AM? Ok thanks :ok_hand:
Are we allowed to add some code (variables initialization) to the __init__ method of EarlyStopping class?
But the problematic case for me is what should happen when the value is between min and min+tolerance.
"EarlyStopping.stop_criterion instructions seem a bit contradictory: The docstring states that patience is ""Maximum number of epochs with unsuccessful updates"", implying that this many non-succesful rounds in row are allowed without outputting true, while the text above the cells says that we output True as soon as we have been unsuccessful ""for patience epochs"" in a row, implying that only patience-1 non-succesful rounds are allowed. I'm assuming that the latter is the case?"
"Hey! If I understand correctly from your description, it sounds like you’ve used something like val_errors[-1] in your implementation and you did not iterate over the last patience number of errors in the array or used them as a slice. If that’s the case, then your implementation actually is unable to stop early, unless you somehow globally decrease the patience. Comparing current local minimum with just one last error value and then decreasing the patience (locally, I presume) has no effect on further epochs since you do not accumulate the number of consequently increasing errors."
"Hey, I have a doubt about the early stopping in the third assignment! Since in the training phase we are calling the stop_criterion at each epoch, I’ve only considered the last element of the array and the minimum element (decreasing the patience by 1 if required). It works correctly during the training phase, I’m wondering why I’ve got 0 points there. @Dmitry Sergeev (TA)"
"Hi, import random is not allowed?"
"Hi, the deadlines are always on Mondays, so for this particular round the deadline is tomorrow. You can check all the dates (exercise releases, deadlines, etc.) in the first lecture"
"Hi, when is the deadline for this round?
(And where does it say?)"
"Hi. Just for clarification, we should just submit the 3_reg and it would submit also saved np arrays. right?"
I cannot find any specific time for the deadlines in the first lecture slides. And haven’t the deadlines been at 6a.m. on Tuesday previously? Has it changed?
"I would assume that it should be reseted, but since this wasn't clearly indicated, I thought I should ask."
"If you sometimes get a bad result in early stop you may want to read Dmitry Sergeev's clarifying post yesterday, regarding when to stop (stopping too early gives bad results)"
"In early stopping, do we reset the patience check each time we find a new minimum, or do we keep it as is. For example let's say we have tolerance of 0 patiance of 2 and errors of 0.5, 0.6, 0.4, 0.5, 0.3, should the execution stop after 0.4 or 0.3? (assuming we start with empty array) (edited)"
"In “Regularization by reducing model capacity” the task says “one hidden layer with 5 units, tanh nonlinearity and a linear output layer”. Does this mean [1, 5] -> tanh -> [5, 5] -> tanh [5, 1] or [1, 5] -> tanh -> [5, 1] (eg, is the “hidden layer” tanh -> [5, 5] -> tanh or just tanh)? (edited)"
"I’m globally decreasing the patience. It is a variable attached to the early_stop object, thus by updating (self.patience -= 1), I will keep control over past errors. And it is also much more efficient once we are calling the the function at each epoch @Dmitry Sergeev (TA)"
"Just make sure you can run each cell individually and you should be fine, if I understood correctly"
Lecturer said the deadline was on Tuesday morning. https://deep-learning-aalto.slack.com/archives/CFY63U23Y/p1552239035086800 (edited)
"Okay, that’s useful information, thanks!"
Or that's my interpretation
"Since in practice, you found the same minimum, not a new one. It should not reset."
"So, the 3_mlp.pth also gets submitted when we submit the 3_reg from the assignments tab, right?"
Some of the cells in 31 may take long (= not very optimized solution) but still be correct. The validation script just timeouts before they are completely run
Thanks. It's ok :smile:
"That would also be my logical interpretation, but then in an another answer it was said that the unsuccessful updates should be consecutive: https://deep-learning-aalto.slack.com/archives/CFWJGAFFE/p1552549557037200"
"That's true. It's a design choice in the end and in practice you could use either or, but since I don't know how strict the grader is, it left me wondering."
This would hint that when the value is between min and min+tolerance the counter should be reset
"To my understanding, the first exercise had its deadline on Monday night, the second had it on Tuesday afternoon (because the lecturer said it in chat) and this one I have no idea.
It would be helpful to know!! :neutral_face:"
"We should be waiting for patience epochs before returning True. I believe the texts in the docstring and above the cell do not contradict each other, since “Maximum number of epochs with unsuccessful updates” is the same as waiting “for patience epochs” in a row. In both cases you need to check at most patience number of epochs to make a decision  regarding stopping."
"Well, I guess comparing this task to how the network was defined earlier (in ""Define a multi-layer perceptron (MLP) network with two hidden layers"") should give you a clue (given that annotation is consistent). That would be [1, 5] -> tanh -> [5, 1] (edited)"
"When 32_hyperparameter_search says ""You are allowed to use only modules imported in the previos cell"", it means the cell with all the imports, right? Not literally the previous cell, which sets the device and doesn't import anything. (edited)"
"Yeah I'm having the same problem. Dunno what's up with that, 32 worked fine and fast."
Yes
"Yes, it should be reseted if a new local minimum is found or, basically, in any case of non-consecutive changes of validation error, as discussed in my post above"
"Yes, of course :)"
"Yes, that was for exercise 2. Can I assume that holds for all future exercises?"
Yes. the hyperparameters array is saved to 3_random_search.npz. you can check your 3_reg folder to make sure everything is there bf submitting.
Your function should return false
"Yup, decided to just submit it. There was some talk about it possibly taking too long and still being valid"
and keep the same count towards patience
"and the main problem is that, ok, most of the times I get a good result. (test loss around 9%), but sometimes I get a real bad result (test loss around 30%)"
"but why? I was trying to understand, but it doesn’t make sense for me. If the inputs are always the same, shouldnt it output same results?"
"hi, I’m getting different results for each time I run the # Let's train the network with early stopping cell. Shoud this happen?"
"it depends on what you do, it should be ok in principle"
okay. I do the same.
really interesting. Thank you!
that is correct
this is normal
yes
"yes, it's Tuesday 6AM (edited)"
you initialize the weights differently and that affects
