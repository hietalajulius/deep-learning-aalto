0
"**Solution:** For anyone having the same problem - make sure you do not iterate over batches inside your MLPBatch class. Since both forward and backward methods already support batch processing, it is sufficient to call them without additional looping"
108kb
@Alexander Ilin Is it ok if my results are similar to Niko's? I mean would be any problems with autograder due to different shapes of gradients?
@Alexander Ilin Okay got it now thanks!
@Charlotta is your problem fixed?
@Hai To (TA)
@Syed Do you normalise your data during training/testing? Your plot looks very similar to the ones that occur with data normalisation but in this particular exercise there is no need for any data preprocessing
"Ah ok thank you, it seems I misunderstood completely. It works now"
"Ah, thanks, because fc1 is Linear type instance, I can call like self.fc1.forward(x).

But does this self.activation_fn1 = Tanh() do anything? Why don’t I just calculate tanh in the function directly?"
"Alright. I was calling y, because it needed to know the shape of y, but I can make it same as the shape of dy.

Can you look at this picture and tell me how to compare my results with numerical solution.."
"And I still have problems as I mentioned before. First I cannot save the assignment. Second I cannot submit it. I tried several times this morning, but it is either not in the TA's record and not shown in my jupyter lab. The unexception message is displayed in my previous messages."
"And you can avoid having to calculate the gradients every time you pass a data sample by combining the data into batches and avoid extra calculations this way. That's why I said that a simple matrix multiplication will do this trick for you, if you think how matrix multiplication works you can see that it exactly does this combination by adding the individual contributions for every data example."
Another possible solution would be to use outer product of two arrays instead of the inner product of reshaped arrays
Are u using Triton for some other purposes?
"But surely ""making it so that dW has the correct dimensions"" is not the right approach to the issue, is it? There is an actual semantic reason for the whole gradient computation.

I am still very confused by the batch gradients. For instance in the case of batch dW, we have the following:

dy ... (batch_size, ysize)
W ... (ysize, xsize)

and we need to get

dW ... (ysize, xsize)

I do see how to somehow make this fit but I see no straightforward way of making it right.

Why are dW and batch dW supposed to have the same shape? Surely we can get a different gradient for each point in the batch?"
But this as an output for the trained model:
Can you clarify it a bit? Pleas.
"Consider each layer as a  function in  which:
forward: x --> F --> y
backward: dx <-- B <-- dy
You just need dy (which comes from the next layer) in current layer’s backward. e.g. in fc1.backward(dy), dy is the output of dy = fc2.backward(dy_prime). (Just as a simple example without activation functions)."
"Could I get a review of this please? I still disagree about this being my mistake since I believe that I have completed the task according to the requirements (using the variable  batch_size) and I do not think that the hidden test running from a different Python scope than the rest of the notebook is a good enough reason to get a point penalty, when the underlying problem has been solved correctly."
Do you know there is some other place I can delete some files
"Finally, it can save the file. I follow the HaiTo's words and remove exercise one in deeplearning folder. Then ex2 can be saved successfully."
"For this MLP function, backward thing. How to approach it? I did with a=activationfuct2.backward(y)
Then dx=activationfuc1.backward(a)
Then dx=dy * dx

Is this the right approach?
I don't know if I have to write anything about the weight or anything"
"Great, thanks, this is what I was looking for! So it is indeed the sum of the individual sample gradients (and can be done by matrix multiplication). Thanks again for the help, I'm convinced this should have been mentioned more explicitly in the lecture."
"Hello, I have a question about how to use the given function for numerical gradients. The example in the notebook is ""dy_num = numerical_gradient(lambda y: loss.forward(y, target), y)"", that is without an activation function. If we have a defined ""y = act_fn.forward(x)"", should we replace the y's with x's in the numerical_gradient parameters, to find the numerical gradient with respect to input? I would think yes, but somehow I only get matching results when I keep them ""y""."
"Hello, I received a late submission penalty, even if my timestamp verifies a submission few hours early"
Here is the final solution from IT service.
"Hi! First, you need to get the gradient of the ReLU function wrt the inputs x, that will give you dy/dx. You can read about different activation functions and their gradients in this nice article - https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6. A small hint - the gradient dy/dx will be a zeros and ones array which you can get from a boolean vector.

Next, you will need to calculate dc/dx using the formula you’ve written above. Notice that dc/dy is given to you as a function argument, so you just need to multiply those two"
"Hi, Could I make sure the deadline is 6:00 a.m of coming Tuesday"
"Hi, I checked in university machine"
"Hi.
Can someone help me identify the problem in this? (edited)"
"Hi. Bit confused about the Relu function. Do I have to call the function from above, to make c? What is my target value, if my output is from the forward function y=f(x). How am I suppose to differentiate it wrt to x for example : dc/dx = dc/dy * dy/dx.....  Where can I get that dy/dx gradient? for the Relu function.. Its super confusing. If anyone can comment on it."
"Hi. I'm having trouble in the backprop through a linear layer exercise. If I understood correctly, the dW should equal to the dy * dy/dW. However, I'm stuck with the issue where I can't multiply these vectors together, because they have different shapes (3,) and (2,)

I've tried to transpose the dy/dW but it doesn't change the shape of the vector (edited)"
How?
I actually had the same problem @Alexander Ilin
I am having difficulties using the numerical_gradients function both in ReLU and Tanh exercises. Can someone guide me how to use it properly?
"I am not sure what you mean by ""which sample to use"", but indeed you need dy and x to calculate dW. You need to have into account the dimensions of x and dy and make it so that dW has the correct dimensions. It is just done with simple matrix/vector multiplications."
I did not get it
I didn't do any normalization
I do not understand what you are doing. There is no need to use loss.forward() to test the gradients through the activation function. You have to test the gradient wrt to x in y = act_fn.forward(x).
"I feel there is an error in the MLPBatch_numeric test. For me, it has failed with the trace going to linear_backward_batch(dy, x, W, b), and the line db = np.dot(dy.T, np.ones(batch_size)). The error is ValueError: shapes (1,5) and (10,) not aligned: 5 (dim 1) != 10 (dim 0), which would mean that the value of batch_size has been defined to be 10 (the value used by my own test visible during the round), even though the hidden test used the value 5."
"I guess you could think it this way:
You pass the first sample of the data, and calculate the gradients and the updates to the weights (without changing the weights yet). Then for the second sample, you do the same. When you have passed all the data, then you update the weights by the sum of the updates you have calculated before"
"I have a question about MLP part of the exercise: Inside class MLP in the function backward(), how do I calculate dy/dx that is needed in the multiplication with parameter ""dy""? What is the actual formula of y? (edited)"
"I have about 950mb available :smile: If you have empty space, it’s possible that you have a lot of small files. Have you checked that?"
"I have question about linear layer that supports batch processing: We are given dy, the gradient of a loss w.r.t. outputs y, shape (batch_size, ysize). To my understanding, the shape of dy/db, the gradient of outputs w.r.t. b is shape (ysize,). Then we get db, the gradient of loss w.r.t. b from product rule: db = dy * dy/db. How can this product of shapes (batch_size, ysize) and (ysize,) result in shape (ysize,) as is defined?"
"I have the same question. In ReLU.backward, I used vector (x > 0) instead of (self.x > 0), but for some reason my test case seemed to work. Does this have something to do with Python scoping rules (which I have no knowledge of)?

I guess that the code in class method ReLu.backward finds the 'x' from the module earlier, and this is why it worked (x was used for the same purpose). What I don't understand is, why it does not work with the autograder code test_ReLU()? It seems to set x in the same way as my test case.

So yes, there is a mistake, but I wonder why the autograder did not do the same scoping?"
I have the same situation as Leinonen. So grading test that fails works in the notebook.
"I know this, but the comments in the code have specifically asked to do just that?"
I may check it again early in the morning using university computer.
I mean I did not know what is smb
I missed the second exercise completely. I didn't even fetch it. I'd like to still try to solve it but it is not (anymore?) fetchable in jupyter.cs.aalto.fi?
"I summed along the first axis and it worked... But it was a completely arbitrary thing that I've tried. There is no explanation in the slides.

Can anyone confirm that summing is the way to go and explain why it's better than say averaging?

EDIT: Just to clarify, I'm talking about taking the sum of gradients within a batch as opposed to taking each of them separately which would result in a wrong (at least according to the assert in the notebook) shape. (edited)"
"I think in both our cases, obviously we had the correct gradient, just accidentally applied it to the wrong thing since they look so similar and its easy to typo it and not see the mistake … hence why I was wondering if we could get that reviewed"
I tried to clean the temporary memory
I will try it now
I'm getting this as the output for the cell that compares y and dy (for batch neural network functions): (edited)
"I'm wondering the same thing, I do not either understand why the dW shape does not depend on batch size. In the numerical gradient case the dW term is summed along the axis, but I do not understand why?"
"I've tested my theory too, if the test would have been done this way (i.e. in the global scope as everything else), it would have passed. It is also the only way the test could have been done according to the specifications provided by the comments of linear_backward_batch(dy, x, W, b), where the variable name batch_size is used. (edited)"
"In linear_backward_batch(), both dy and x contain a batch of arrays, i.e. multiple samples in a matrix with shape (batch_size,ysize) and (batch_size,xsize), respectively. According to the instructions, the function should return dW of shape (ysize,xsize). That means that dW does not vary from sample to sample in the batch. However, my calculation of dW includes both dy and x which means that I don't know which sample to use. Is there a way to calculate dW without dy or x, or should I use some average value of dy and x to calculate dW? Or calculate dW for each sample, and then return an average of the dW values (that would be averaged stochastic gradient descent, I reckon)? Any hints on calculating dW for batches?"
"In that line you  have used self.activation_fn2.backward(self.fc2.x). In fact, when you have already saved x in the fc2, why you want to pass it as the argument? (You are passing x while fc2 has it already and you can use it inside the backward function)."
"In the backward pass you need to propagate the gradient of the loss function dy from the end to the start of the network. You already should have the logic of the forward pass defined in the  forward method where you propagated input x from start to the end, so now you just need to reverse this logic and backpropagate dy"
"In the numerical gradient case the dW term is summed along the axis

@Vili I think it's not summed along the axis but instead multiplied with dy (product rule) because numerical gradient is gradient of y, and the analytical is gradient of c (the product results to the diagonal in this case when dy is vector of 1s)"
"Interesting point about frameworks like Pytorch is that they are managing gradient automatically. Mostly, in Pytorch, tensors have requires_grad property which (I think) save the forward value if you set them True and in backward function will use that."
It works finally
Its just the vanilla test code in the relevant cell
"Let's not get to pytorch yet, my cpu has 200% load in this python code :slightly_smiling_face:"
"Like here dy (array): Gradient of a loss wrt outputs, shape (batch_size, ysize). It probably wasn't mean to be interpreted as a variable after all, but I actively chose no to do something like dy.shape[0] because I feel it would be contrary to the what the task tells me to use; batch_size definitely looks like a variable name (especially since it is used elsewhere). This is only -1p now, but now I'm afraid that I will lose even more points in the upcoming weeks because the tasks could be interpreted in multiple ways."
"MLP and python class. Not being very familiar with classes, but I am trying to call in the forward “x=self.fc1(x) and I get error ‘Linear’ object is not callable.

I have no idea why, in the last week’s exercise this worked. Isn’t this the way the init definitions are called?"
"More specifically,
x -> fc1 -> tanh1 -> fc2 -> tanh2 -> fc3 -> y
dx <- fc1.b <- tanh1.b <- fc2.b <- tanh2.b <- fc3.b <- dy"
My last version cannot be saved until this moment
"No, I did not"
"Of course, that tanh that was defined earlier in the code. Thanks."
"Ok got it working, the solution was to turn the shape into (3,1) and (2,1)"
Ok. Thanks!
"Or, actually, this is an issue of Python global/local scopes. It seems that the function did create a local variable called batch_size (not directly visible to my functions) instead of reassigning the global one. It's understandable, however, there is no clue that the hidden test would be run from within a function and not outright as the commands in the global scope (exactly like the provided ""preliminary"" test). If the reassignment had been made outside the hidden test function, the test would have passed. (edited)"
Same issue here for Relu activation. The dimensions of numerical_gradient are incorrect...
"Short answer, no. As you mentioned, chain-rule is used so that we don’t want to calculate all derivations from the last to the current layer. dy is the (aggregated) gradient from the last layers and in this layer we should multiply that with current gradient and backpropagate the result as dy for previous layer. It’s true for both neurons and activation functions."
So regarding the return value: I don't need to multiply each partial derivative together but I return the last derivative in the chain?
So the gradient size does not depend on the batch size
"So, in the MLP backward I can calculate the gradients using chain rule. This has five partial derivatives from the different parts inside the network.
The middle layers have tanh triggering function, so I need to call the backward of this class.
These middle layers are fc1 and fc2 and they are Linear class. This class stores the neuron values in the parameter x, so I calculate the partial derivative at this value x, eg.
self.activation_fn2.backward(self.fc2.x)
I will use the value x, because the tanh(x) derivative is 1-(tanh(x))^2, calculated at x.

Let’s look at the first middle layer which has 10 neurons. This layer has a weight matrix, let’s call it W1 (size 10x2). To calculate the derivate on the linear layer we will call

dX1/dx, dW1, db1 = linear_backward(dy, self.fc1.x, self.fc1.W, self.fc1.b)

But what is the dy here? Is that the gradient calculated in the next middle layer (with 20 neurons).

So to calculate all the partial derivatives I need start from the output layer, then backpropagate and pass the gradient to the previous layer. When I have calculated all partials, I will multiply those together and that is the value the function will return?"
Summing works because it is equivalent with multiplying with the dy-vector since it happens to be a vector of all ones in the given test-case. If you try with some other dy-vector mere summing no longer gives the correct answer :wink:
Thanks
Thanks for this. I'll explore what I'm doing wrong!
"The number of weights is the same regardless of the batch size, so the gradient (which is used to update them) has always the same size too."
The shapes are correct...
Which shows that the model is being trained correctly (I think?). So why is the output for comparing y and dy incorrect?
"Why is that true in the batch case, though? There, we have several functions that we're computing gradients of! That gives us several results. The required output, however, is only one result. Is there only one specific operation to perform when combining those results into one? If so, why?"
"Yeah the issue is python scoping. In the exercise, there’s a cell that does x = blah then ReLU(x), so its “safe” to use x in the backward function for relu. But that’s not true for the tests where you’re meant to use self.x (eg, the cached value, not the one in the outer scope)."
Yes I can or np.diag(). I was just thinking if this causes some problems in automatic grading system. The first elements seems also differ with one decimal..
"Yes, thank you!"
"Yes, that's probably the case. I now managed to get the analytical and numerical gradients to mach by just summing things, but no idea why does it seems to be working"
You need to use forward and backward functions of the linear layers and the activation functions.
You only have variables x when you apply the function. Check how to use lambda functions in python.
"You should use the activation function instead of the loss one, numerical_gradient(lambda y: act_fn.forward(y), x)"
"You shouldn’t call forward function in the backward. In general, forward function is called first (in the code), then the inputs will set (like x in this example),  then gradient (backward) would define based on that input."
Your lambda doesn't use its parameter y.
and confirm nothing else there
"but it's weird, how big are your 2nd assignment files together?"
can you send me privately your username?
could you explain a little bit more
except for deep learning assignment
"great, thank you"
http://scicomp.aalto.fi/aalto/jupyterhub-data.html
https://deep-learning-aalto.slack.com/archives/CFY63U23Y/p1552239035086800
"i.e. after test_MLPBatch_numerically is called, it should be 5?"
"is it possible to get the grade reviewed if our answer is “technically” correct, but was marked incorrect by the autograder due to a typo (in this case, s/x/self.x/)?"
"it is updated, it will be updated in your directory soon. sorry"
"it says 260mb of 1gb used for me, have you checked this?"
looks the same i think
"maybe you can open the terminal and check how much storage you have used in your /notebooks dir , jupyterhub allows up to 1gb for each students."
much less than that
"no, I do not have things in the drive"
self.fc2.x creates shape mismatch error in the tanh backwards. But this worked: self.activation_fn2.backward(self.activation_fn1) as it stores the x values of that layer. In my code it looks like self.fc2.x stores the values after tanh.forward.
should look more like this i guess
"similar to your self-defined python class Linear, you need to do self.activation_fn1 = Tanh() for your self-defined Tanh class to get the object and use its attribute forward() in the forward() func of MyMLP class"
the assignments will be put back soon.
"the builtin classes from torch.nn call .forward() under the hook. you can take a look at this
https://discuss.pytorch.org/t/predict-output-by-model-does-not-need-call-forward/1489/2"
to see if your quota is exceeding
try to understand how numerical_gradient works and what we want to achieve in the backward function. results are as expected.
we'll take a look at this
what about your trained model? can you share its screenshot?
you can tryy it with smb
you cannot get exactly the same results with numerical computations.
"you should call .forward() instead, pytorch modules are typically callable, our classes are not callable."
"you should not have used global variables in your function, that is not safe and that is why it failed. (edited)"
