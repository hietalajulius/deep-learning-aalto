{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import getLoader, path_to_train, path_to_test,loader_batch_size_train,loader_batch_size_test, path_to_slack,loader_batch_size_slack\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths: data/large/processed_train.csv data/large/processed_test.csv data/large/slack_test.csv\n",
      "batch size train: 512\n",
      "batch size test: 5\n",
      "batch size slack: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Paths:\",path_to_train,path_to_test,path_to_slack)\n",
    "print(\"batch size train:\",loader_batch_size_train)\n",
    "print(\"batch size test:\",loader_batch_size_test)\n",
    "print(\"batch size slack:\",loader_batch_size_slack)\n",
    "skip_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dictionary_size, hidden_size, output_size=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(dictionary_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          pad_seqs: Tensor [max_seq_length, batch_size, 1]\n",
    "          seq_lengths: list of sequence lengths\n",
    "          hidden: Tensor [1, batch_size, hidden_size]\n",
    "\n",
    "        Returns:\n",
    "          outputs: Tensor [max_seq_length, batch_size, hidden_size]\n",
    "          hidden: Tensor [1, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        batch_size = pad_seqs.shape[1]\n",
    "        \n",
    "        embedded = self.embedding(pad_seqs).view(pad_seqs.shape[0], pad_seqs.shape[1], -1)\n",
    "\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths, batch_first = False)\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "        _,hidden = self.lstm(packed)\n",
    "        \n",
    "        fc = self.linear(hidden[0])\n",
    "\n",
    "        return fc\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device=device):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "dictionary_size = 20000\n",
    "classifier = Classifier(dictionary_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = getLoader(train=True,mini=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "classifier_optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200 \n",
    "    print(\"Epoch\", epoch+1)\n",
    "    \n",
    "    for i, batch in enumerate(trainloader):\n",
    "        classifier_optimizer.zero_grad()\n",
    "        \n",
    "        pad_input_seqs, input_seq_lengths, target_seqs = batch\n",
    "        batch_size = pad_input_seqs.size(1)\n",
    "        pad_input_seqs, target_seqs = pad_input_seqs.to(device), target_seqs.to(device)\n",
    "\n",
    "        classifier_hidden = classifier.init_hidden(batch_size, device)\n",
    "\n",
    "        classifier_hidden = classifier(pad_input_seqs, input_seq_lengths, classifier_hidden)\n",
    "\n",
    "        loss = criterion(classifier_hidden.view(batch_size,2), target_seqs)\n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        classifier_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1) or i == (len(trainloader) // trainloader.batch_size):\n",
    "            print('[%d, %5d] loss: %.4f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if skip_training:\n",
    "            break\n",
    "    if skip_training:\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier loaded from classifier_model.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk, submit these files together with your notebook\n",
    "classifier_filename = 'classifier_model.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        torch.save(classifier.state_dict(), classifier_filename)\n",
    "        print('Model saved to %s' % (classifier_filename))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    classifier = Classifier(dictionary_size, hidden_size)\n",
    "    classifier.load_state_dict(torch.load(classifier_filename, map_location=lambda storage, loc: storage))\n",
    "    print('Classifier loaded from %s.' % classifier_filename)\n",
    "    classifier = classifier.to(device)\n",
    "    classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = getLoader(train=False,mini=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(classifier, testloader, print_every):\n",
    "    classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(pad_input_seqs, input_seq_lengths, targets, _) in enumerate(testloader):\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            \n",
    "            pad_input_seqs, targets = pad_input_seqs.to(device), targets.to(device)\n",
    "            \n",
    "            init_hidden = classifier.init_hidden(batch_size, device)\n",
    "            output = classifier(pad_input_seqs, input_seq_lengths, init_hidden)\n",
    "            \n",
    "            out_flat = output.detach().numpy().argmax(axis=2)\n",
    "            predicted = torch.tensor(out_flat)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            if (i % print_every == 0):\n",
    "                print(\"Counted:\",total,\"accuracy\",correct / total)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted: 512 accuracy 0.908203125\n",
      "Counted: 512512 accuracy 0.9233754526723277\n",
      "Counted: 1024512 accuracy 0.9225338502623688\n",
      "Final train accuracy: 0.92265078125\n",
      "Counted: 5 accuracy 0.8\n",
      "Counted: 5005 accuracy 0.8253746253746254\n",
      "Counted: 10005 accuracy 0.8277861069465268\n",
      "Counted: 15005 accuracy 0.8276574475174941\n",
      "Counted: 20005 accuracy 0.8273431642089477\n",
      "Counted: 25005 accuracy 0.8277544491101779\n",
      "Counted: 30005 accuracy 0.8283619396767206\n",
      "Counted: 35005 accuracy 0.8287673189544351\n",
      "Counted: 40005 accuracy 0.8293463317085364\n",
      "Counted: 45005 accuracy 0.8294411732029775\n",
      "Counted: 50005 accuracy 0.8285171482851715\n",
      "Counted: 55005 accuracy 0.8275429506408508\n",
      "Counted: 60005 accuracy 0.828197650195817\n",
      "Counted: 65005 accuracy 0.8279670794554265\n",
      "Counted: 70005 accuracy 0.8274123276908792\n",
      "Counted: 75005 accuracy 0.8275448303446437\n",
      "Counted: 80005 accuracy 0.8278107618273858\n",
      "Counted: 85005 accuracy 0.8280924651491088\n",
      "Counted: 90005 accuracy 0.8281317704571968\n",
      "Counted: 95005 accuracy 0.8284721856744381\n",
      "Counted: 100005 accuracy 0.8283485825708714\n",
      "Counted: 105005 accuracy 0.8285414980239036\n",
      "Counted: 110005 accuracy 0.8287077860097268\n",
      "Counted: 115005 accuracy 0.8283726794487196\n",
      "Counted: 120005 accuracy 0.8285321444939794\n",
      "Counted: 125005 accuracy 0.8284548618055277\n",
      "Counted: 130005 accuracy 0.8285219799238491\n",
      "Counted: 135005 accuracy 0.8288581904373912\n",
      "Counted: 140005 accuracy 0.8284061283525589\n",
      "Counted: 145005 accuracy 0.8283576428399021\n",
      "Counted: 150005 accuracy 0.8284190526982433\n",
      "Counted: 155005 accuracy 0.8283087642334118\n",
      "Counted: 160005 accuracy 0.8283491140901846\n",
      "Counted: 165005 accuracy 0.828035514075331\n",
      "Counted: 170005 accuracy 0.8279874121349372\n",
      "Counted: 175005 accuracy 0.8280106282677637\n",
      "Counted: 180005 accuracy 0.8279714452376323\n",
      "Counted: 185005 accuracy 0.8280641063755033\n",
      "Counted: 190005 accuracy 0.8281045235651694\n",
      "Counted: 195005 accuracy 0.8280967154688341\n",
      "Counted: 200005 accuracy 0.8281042973925652\n",
      "Counted: 205005 accuracy 0.8281749225628643\n",
      "Counted: 210005 accuracy 0.8280374276802933\n",
      "Counted: 215005 accuracy 0.8278179577219135\n",
      "Counted: 220005 accuracy 0.8279130019772278\n",
      "Counted: 225005 accuracy 0.8278482700384436\n",
      "Counted: 230005 accuracy 0.8277689615443142\n",
      "Counted: 235005 accuracy 0.8277143039509798\n",
      "Counted: 240005 accuracy 0.8275827586925273\n",
      "Counted: 245005 accuracy 0.8276402522397502\n",
      "Counted: 250005 accuracy 0.8277594448111038\n",
      "Counted: 255005 accuracy 0.8277445540283523\n",
      "Counted: 260005 accuracy 0.8276533143593392\n",
      "Counted: 265005 accuracy 0.8276070262825229\n",
      "Counted: 270005 accuracy 0.827677265235829\n",
      "Counted: 275005 accuracy 0.8275922255958983\n",
      "Counted: 280005 accuracy 0.8275316512205139\n",
      "Counted: 285005 accuracy 0.8275153067490044\n",
      "Counted: 290005 accuracy 0.8275305598179342\n",
      "Counted: 295005 accuracy 0.8276435992610295\n",
      "Counted: 300005 accuracy 0.827819536341061\n",
      "Counted: 305005 accuracy 0.8278618383305192\n",
      "Counted: 310005 accuracy 0.8279124530249512\n",
      "Counted: 315005 accuracy 0.8277328931286805\n",
      "Final test accuracy: 0.827578125\n"
     ]
    }
   ],
   "source": [
    "print(\"Final train accuracy:\",compute_accuracy(classifier,trainloader,500),\"\\n\")\n",
    "print(\"Final test accuracy:\",compute_accuracy(classifier,testloader,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "slackloader = getLoader(train=False,mini=False, slack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_csv(\"data/words.csv\",squeeze=True)\n",
    "index_word = {x:y for x,y in enumerate(word_df[\"0\"])}\n",
    "word_index = {y:x for x,y in enumerate(word_df[\"0\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_slack(classifier, testloader, print_every):\n",
    "    classifier.eval()\n",
    "    negative = 0\n",
    "    positive = 0\n",
    "    total = 0\n",
    "    pos_scores = {}\n",
    "    neg_scores = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (pad_input_seqs, input_seq_lengths, targets , _) in enumerate(testloader):\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            \n",
    "            pad_input_seqs = pad_input_seqs.to(device)\n",
    "            \n",
    "            init_hidden = classifier.init_hidden(batch_size, device)\n",
    "            output = classifier(pad_input_seqs, input_seq_lengths, init_hidden)\n",
    "            \n",
    "            out_flat = output.detach().numpy().argmax(axis=2)\n",
    "            predicted = torch.tensor(out_flat)\n",
    "            \n",
    "            \n",
    "            total += targets.size(0)\n",
    "            positive += (predicted == 1).sum().item()\n",
    "            negative += (predicted == 0).sum().item()\n",
    "\n",
    "            pos_scores.update({i:output.numpy().flatten()[1]})\n",
    "            neg_scores.update({i:output.numpy().flatten()[0]})\n",
    "            \n",
    "\n",
    "            if (total % print_every == 0):\n",
    "                print(\"Counted:\",total,\"positive\",positive / total,\"negative\",negative / total)\n",
    "    return positive, negative, total, pos_scores, neg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted: 200 positive 0.545 negative 0.455\n",
      "Counted: 400 positive 0.5275 negative 0.4725\n",
      "Counted: 600 positive 0.505 negative 0.495\n",
      "Counted: 800 positive 0.50125 negative 0.49875\n",
      "Counted: 1000 positive 0.504 negative 0.496\n"
     ]
    }
   ],
   "source": [
    "pos_count,neg_count,total, pos_scores, neg_scores = evaluate_slack(classifier,slackloader,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_scores = sorted(pos_scores.items(), key=lambda s: -s[1])\n",
    "neg_scores = sorted(neg_scores.items(), key=lambda s: -s[1])\n",
    "listed = list(slackloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive sentence 1\n",
      "set the channel purpose for finding project partners \n",
      "\n",
      "Top Positive sentence 2\n",
      "yes the exercise sessions . thanks ! \n",
      "\n",
      "Top Positive sentence 3\n",
      "in CTX the type torch CTX is actually float doing your CTX CTX will convert torch CTX to torch CTX \n",
      "\n",
      "Top Positive sentence 4\n",
      "and you can avoid having to CTX the CTX every time you pass a data sample by CTX the data into CTX and avoid extra CTX this way . that s why i said that a simple matrix CTX will do this trick for you if you think how matrix CTX works you can see that it exactly does this combination by adding the individual CTX for every data example . \n",
      "\n",
      "Top Positive sentence 5\n",
      "in . CTX in the return value description is returns CTX CTX CTX of the CTX shape CTX length hidden size . hidden CTX new state of the CTX shape batch size hidden size with batch size . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,top in enumerate(pos_scores[:5]):\n",
    "    print(\"Top Positive sentence\",i+1)\n",
    "    sentence = listed[top[0]]\n",
    "    for word in sentence[0].numpy().flatten():\n",
    "        if (word != 2 and word != 3 and word != 0):\n",
    "            print(index_word[word],end=\" \")\n",
    "    print(\"\\n\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Negative sentence 1\n",
      "are there any tutorial sessions this week ? the booking option is not available on CTX edited \n",
      "\n",
      "Top Negative sentence 2\n",
      "when i fetch data and click on it it says empty . i can t seem to download the data . \n",
      "\n",
      "Top Negative sentence 3\n",
      "class CTX nn CTX def init self dictionary size hidden size super CTX self . init self CTX size hidden size self CTX nn CTX dictionary size hidden size self CTX nn CTX hidden size hidden size def forward self pad CTX CTX CTX hidden CTX pad CTX CTX max CTX length batch size CTX CTX list of sequence CTX hidden CTX batch size hidden size returns CTX CTX max CTX length batch size hidden size hidden CTX batch size hidden size your code here pad CTX self CTX pad CTX packed sequence pack CTX sequence pad CTX CTX CTX batch first false input CTX packed sequence CTX in length input CTX CTX CTX collect CTX CTX at different processing steps in this list el for batch size in packed sequence CTX sizes for i in range batch size CTX input CTX el CTX CTX hidden i self CTX CTX hidden i CTX packed sequence CTX el CTX CTX CTX CTX el CTX torch CTX CTX dim packed sequence CTX CTX CTX pad packed sequence packed sequence batch first false CTX CTX CTX CTX CTX CTX CTX return CTX hidden def init hidden self batch size device device return torch CTX batch size self CTX size device device \n",
      "\n",
      "Top Negative sentence 4\n",
      "i didn t get any feedback ? \n",
      "\n",
      "Top Negative sentence 5\n",
      "i m getting this type of loss at the very start is this normal ? loss . loss . loss . loss . loss . loss . loss . loss . loss . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,top in enumerate(neg_scores[:5]):\n",
    "    print(\"Top Negative sentence\",i+1)\n",
    "    sentence = listed[top[0]]\n",
    "    for word in sentence[0].numpy().flatten():\n",
    "        if (word != 2 and word != 3 and word != 0):\n",
    "            print(index_word[word],end=\" \")\n",
    "    print(\"\\n\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
