{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import getLoader, path_to_train, path_to_test,loader_batch_size_train,loader_batch_size_test, path_to_slack,loader_batch_size_slack\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dictionary_size, hidden_size, output_size=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(dictionary_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        \n",
    "        batch_size = pad_seqs.shape[1]\n",
    "        embedded = self.embedding(pad_seqs).view(pad_seqs.shape[0], pad_seqs.shape[1], -1)\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths, batch_first = False)\n",
    "        self.lstm.flatten_parameters()\n",
    "        _,hidden = self.lstm(packed)\n",
    "        fc = self.linear(hidden[0])\n",
    "\n",
    "        return fc\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device=device):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "dictionary_size = 20000\n",
    "classifier = Classifier(dictionary_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = getLoader(train=True,mini=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "classifier_optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200 \n",
    "    print(\"Epoch\", epoch+1)\n",
    "    \n",
    "    for i, batch in enumerate(trainloader):\n",
    "        classifier_optimizer.zero_grad()\n",
    "        pad_input_seqs, input_seq_lengths, target_seqs = batch\n",
    "        batch_size = pad_input_seqs.size(1)\n",
    "        pad_input_seqs, target_seqs = pad_input_seqs.to(device), target_seqs.to(device)\n",
    "        classifier_hidden = classifier.init_hidden(batch_size, device)\n",
    "        classifier_hidden = classifier(pad_input_seqs, input_seq_lengths, classifier_hidden)\n",
    "        loss = criterion(classifier_hidden.view(batch_size,2), target_seqs)\n",
    "        loss.backward()\n",
    "        \n",
    "        classifier_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1) or i == (len(trainloader) // trainloader.batch_size):\n",
    "            print('[%d, %5d] loss: %.4f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if skip_training:\n",
    "            break\n",
    "    if skip_training:\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier loaded from classifier_model.pth.\n"
     ]
    }
   ],
   "source": [
    "classifier_filename = 'classifier_model.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        torch.save(classifier.state_dict(), classifier_filename)\n",
    "        print('Model saved to %s' % (classifier_filename))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    classifier = Classifier(dictionary_size, hidden_size)\n",
    "    classifier.load_state_dict(torch.load(classifier_filename, map_location=lambda storage, loc: storage))\n",
    "    print('Classifier loaded from %s.' % classifier_filename)\n",
    "    classifier = classifier.to(device)\n",
    "    classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = getLoader(train=False,mini=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(classifier, testloader, print_every):\n",
    "    classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i,(pad_input_seqs, input_seq_lengths, targets, _) in enumerate(testloader):\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            \n",
    "            pad_input_seqs, targets = pad_input_seqs.to(device), targets.to(device)\n",
    "            \n",
    "            init_hidden = classifier.init_hidden(batch_size, device)\n",
    "            output = classifier(pad_input_seqs, input_seq_lengths, init_hidden)\n",
    "            \n",
    "            out_flat = output.detach().numpy().argmax(axis=2)\n",
    "            predicted = torch.tensor(out_flat)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            if (i % print_every == 0):\n",
    "                print(\"Counted:\",total,\"accuracy\",correct / total)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:Counted: 512 accuracy 0.908203125\n",
      "Counted: 512512 accuracy 0.9233754526723277\n",
      "Counted: 1024512 accuracy 0.9225338502623688\n",
      "Final train accuracy: 0.92265078125\n",
      "\n",
      "Test:Counted: 100005 accuracy 0.8283485825708714\n",
      "Counted: 200005 accuracy 0.8281042973925652\n",
      "Counted: 300005 accuracy 0.827819536341061\n",
      "Final test accuracy: 0.827578125\n"
     ]
    }
   ],
   "source": [
    "print(\"Final train accuracy:\",compute_accuracy(classifier,trainloader,500),\"\\n\")\n",
    "print(\"Final test accuracy:\",compute_accuracy(classifier,testloader,10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the distribution of positive and negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "slackloader = getLoader(train=False,mini=False, slack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_csv(\"data/words.csv\",squeeze=True)\n",
    "index_word = {x:y for x,y in enumerate(word_df[\"0\"])}\n",
    "word_index = {y:x for x,y in enumerate(word_df[\"0\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_slack(classifier, testloader, print_every):\n",
    "    classifier.eval()\n",
    "    negative = 0\n",
    "    positive = 0\n",
    "    total = 0\n",
    "    pos_scores = {}\n",
    "    neg_scores = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (pad_input_seqs, input_seq_lengths, targets) in enumerate(testloader):\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            \n",
    "            pad_input_seqs = pad_input_seqs.to(device)\n",
    "            \n",
    "            init_hidden = classifier.init_hidden(batch_size, device)\n",
    "            output = classifier(pad_input_seqs, input_seq_lengths, init_hidden)\n",
    "            \n",
    "            out_flat = output.detach().numpy().argmax(axis=2)\n",
    "            predicted = torch.tensor(out_flat)\n",
    "            \n",
    "            \n",
    "            total += targets.size(0)\n",
    "            positive += (predicted == 1).sum().item()\n",
    "            negative += (predicted == 0).sum().item()\n",
    "\n",
    "            pos_scores.update({i:output.numpy().flatten()[1]})\n",
    "            neg_scores.update({i:output.numpy().flatten()[0]})\n",
    "            \n",
    "            if (total % print_every == 0):\n",
    "                print(\"Counted:\",total,\"positive\",positive / total,\"negative\",negative / total)\n",
    "    return positive, negative, total, pos_scores, neg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted: 200 positive 0.545 negative 0.455\n",
      "Counted: 400 positive 0.5275 negative 0.4725\n",
      "Counted: 600 positive 0.505 negative 0.495\n",
      "Counted: 800 positive 0.50125 negative 0.49875\n",
      "Counted: 1000 positive 0.504 negative 0.496\n"
     ]
    }
   ],
   "source": [
    "pos_count,neg_count,total, pos_scores, neg_scores = evaluate_slack(classifier,slackloader,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_scores = sorted(pos_scores.items(), key=lambda s: -s[1])\n",
    "neg_scores = sorted(neg_scores.items(), key=lambda s: -s[1])\n",
    "listed = list(slackloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the top positive tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive sentence 1\n",
      "set the channel purpose for finding project partners \n",
      "\n",
      "Top Positive sentence 2\n",
      "yes the exercise sessions . thanks ! \n",
      "\n",
      "Top Positive sentence 3\n",
      "in CTX the type torch CTX is actually float doing your CTX CTX will convert torch CTX to torch CTX \n",
      "\n",
      "Top Positive sentence 4\n",
      "and you can avoid having to CTX the CTX every time you pass a data sample by CTX the data into CTX and avoid extra CTX this way . that s why i said that a simple matrix CTX will do this trick for you if you think how matrix CTX works you can see that it exactly does this combination by adding the individual CTX for every data example . \n",
      "\n",
      "Top Positive sentence 5\n",
      "in . CTX in the return value description is returns CTX CTX CTX of the CTX shape CTX length hidden size . hidden CTX new state of the CTX shape batch size hidden size with batch size . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,top in enumerate(pos_scores[:5]):\n",
    "    print(\"Top Positive sentence\",i+1)\n",
    "    sentence = listed[top[0]]\n",
    "    for word in sentence[0].numpy().flatten():\n",
    "        if (word != 2 and word != 3 and word != 0):\n",
    "            print(index_word[word],end=\" \")\n",
    "    print(\"\\n\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the top negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Negative sentence 1\n",
      "are there any tutorial sessions this week ? the booking option is not available on CTX edited \n",
      "\n",
      "Top Negative sentence 2\n",
      "when i fetch data and click on it it says empty . i can t seem to download the data . \n",
      "\n",
      "Top Negative sentence 3\n",
      "class CTX nn CTX def init self dictionary size hidden size super CTX self . init self CTX size hidden size self CTX nn CTX dictionary size hidden size self CTX nn CTX hidden size hidden size def forward self pad CTX CTX CTX hidden CTX pad CTX CTX max CTX length batch size CTX CTX list of sequence CTX hidden CTX batch size hidden size returns CTX CTX max CTX length batch size hidden size hidden CTX batch size hidden size your code here pad CTX self CTX pad CTX packed sequence pack CTX sequence pad CTX CTX CTX batch first false input CTX packed sequence CTX in length input CTX CTX CTX collect CTX CTX at different processing steps in this list el for batch size in packed sequence CTX sizes for i in range batch size CTX input CTX el CTX CTX hidden i self CTX CTX hidden i CTX packed sequence CTX el CTX CTX CTX CTX el CTX torch CTX CTX dim packed sequence CTX CTX CTX pad packed sequence packed sequence batch first false CTX CTX CTX CTX CTX CTX CTX return CTX hidden def init hidden self batch size device device return torch CTX batch size self CTX size device device \n",
      "\n",
      "Top Negative sentence 4\n",
      "i didn t get any feedback ? \n",
      "\n",
      "Top Negative sentence 5\n",
      "i m getting this type of loss at the very start is this normal ? loss . loss . loss . loss . loss . loss . loss . loss . loss . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,top in enumerate(neg_scores[:5]):\n",
    "    print(\"Top Negative sentence\",i+1)\n",
    "    sentence = listed[top[0]]\n",
    "    for word in sentence[0].numpy().flatten():\n",
    "        if (word != 2 and word != 3 and word != 0):\n",
    "            print(index_word[word],end=\" \")\n",
    "    print(\"\\n\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your own sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_csv(\"data/words.csv\",squeeze=True)\n",
    "index_word = {x:y for x,y in enumerate(word_df[\"0\"])}\n",
    "word_index = {y:x for x,y in enumerate(word_df[\"0\"])}\n",
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def indices_func(sentence):\n",
    "    indices = [[[2]]]\n",
    "    for word in nlp(cleanString(sentence)):\n",
    "        try:\n",
    "            indices.append([[word_index[word.text.lower()]]])\n",
    "        except:\n",
    "            indices.append([[1]])\n",
    "            \n",
    "    indices.append([[3]])\n",
    "    return indices\n",
    "\n",
    "def cleanString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def replace(x):\n",
    "    if (x==4): \n",
    "        return 1 \n",
    "    else: \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your sentence? (type \"exit\" to quit) \n",
      "it was a good day\n",
      "Sentiment:\n",
      "Positive \n",
      "\n",
      "What is your sentence? (type \"exit\" to quit) \n",
      "today could have been better\n",
      "Sentiment:\n",
      "Negative \n",
      "\n",
      "What is your sentence? (type \"exit\" to quit) \n",
      "today could not have been more perfect\n",
      "Sentiment:\n",
      "Negative \n",
      "\n",
      "What is your sentence? (type \"exit\" to quit) \n",
      "the above result is surprising but not in a good way\n",
      "Sentiment:\n",
      "Negative \n",
      "\n",
      "What is your sentence? (type \"exit\" to quit) \n",
      "i am fairly positive we can improve the accuracy\n",
      "Sentiment:\n",
      "Positive \n",
      "\n",
      "What is your sentence? (type \"exit\" to quit) \n",
      "perfect\n",
      "Sentiment:\n",
      "Positive \n",
      "\n",
      "What is your sentence? (type \"exit\" to quit) \n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "while (sentence != \"exit\"):\n",
    "    sentence = input('What is your sentence? (type \"exit\" to quit) \\n').lower()\n",
    "    if (sentence == \"exit\"):\n",
    "        break\n",
    "    indices = indices_func(cleanString(sentence))\n",
    "    indices_tensor = torch.tensor(indices)\n",
    "    lens = torch.tensor([len(indices)])\n",
    "    init_hidden = classifier.init_hidden(1, device)\n",
    "    output = classifier(indices_tensor, lens, init_hidden)\n",
    "    final = output.detach().numpy().flatten()\n",
    "    print(\"Sentiment:\")\n",
    "    if (final[0]>final[1]):\n",
    "        print(\"Negative \\n\")\n",
    "    else:\n",
    "        print(\"Positive \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
