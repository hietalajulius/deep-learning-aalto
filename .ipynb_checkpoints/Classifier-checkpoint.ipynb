{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import getLoader, path_to_train, path_to_test,loader_batch_size_train,loader_batch_size_test, path_to_slack,loader_batch_size_slack\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths: data/large/processed_train.csv data/large/processed_test.csv data/large/slack_test.csv\n",
      "batch size train: 512\n",
      "batch size test: 5\n",
      "batch size slack: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Paths:\",path_to_train,path_to_test,path_to_slack)\n",
    "print(\"batch size train:\",loader_batch_size_train)\n",
    "print(\"batch size test:\",loader_batch_size_test)\n",
    "print(\"batch size slack:\",loader_batch_size_slack)\n",
    "skip_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dictionary_size, hidden_size, output_size=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(dictionary_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, pad_seqs, seq_lengths, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          pad_seqs: Tensor [max_seq_length, batch_size, 1]\n",
    "          seq_lengths: list of sequence lengths\n",
    "          hidden: Tensor [1, batch_size, hidden_size]\n",
    "\n",
    "        Returns:\n",
    "          outputs: Tensor [max_seq_length, batch_size, hidden_size]\n",
    "          hidden: Tensor [1, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        batch_size = pad_seqs.shape[1]\n",
    "        \n",
    "        embedded = self.embedding(pad_seqs).view(pad_seqs.shape[0], pad_seqs.shape[1], -1)\n",
    "\n",
    "        packed = pack_padded_sequence(embedded, seq_lengths, batch_first = False)\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "        _,hidden = self.lstm(packed)\n",
    "        \n",
    "        fc = self.linear(hidden[0])\n",
    "\n",
    "        return fc\n",
    "\n",
    "    def init_hidden(self, batch_size=1, device=device):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "dictionary_size = 20000\n",
    "classifier = Classifier(dictionary_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = getLoader(train=True,mini=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "in: torch.Size([37, 512, 1])\n",
      "tensor([[[ 0.0857,  0.1926],\n",
      "         [-0.0230,  0.1797],\n",
      "         [ 0.0260,  0.0842],\n",
      "         ...,\n",
      "         [ 0.0713,  0.1668],\n",
      "         [ 0.0713,  0.1668],\n",
      "         [ 0.0513,  0.0523]]], grad_fn=<AddBackward0>)\n",
      "out: torch.Size([1, 512, 2])\n"
     ]
    }
   ],
   "source": [
    "#Quick output test\n",
    "for i, batch in enumerate(trainloader):\n",
    "    print(\"iter\", i)\n",
    "    pad_input_seqs, input_seq_lengths, pad_target_seqs, target_seq_lengths = batch\n",
    "    batch_size = pad_input_seqs.size(1)\n",
    "    pad_input_seqs, pad_target_seqs = pad_input_seqs.to(device), pad_target_seqs.to(device)\n",
    "\n",
    "    classifier_hidden = classifier.init_hidden(batch_size, device)\n",
    "    print(\"in:\",pad_input_seqs.size())\n",
    "    classifier_hidden = classifier(pad_input_seqs, input_seq_lengths, classifier_hidden)\n",
    "    print(classifier_hidden)\n",
    "    print(\"out:\",classifier_hidden.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "classifier_optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = 200 \n",
    "    print(\"Epoch\", epoch+1)\n",
    "    \n",
    "    for i, batch in enumerate(trainloader):\n",
    "        classifier_optimizer.zero_grad()\n",
    "        \n",
    "        pad_input_seqs, input_seq_lengths, pad_target_seqs, target_seq_lengths = batch\n",
    "        batch_size = pad_input_seqs.size(1)\n",
    "        pad_input_seqs, pad_target_seqs = pad_input_seqs.to(device), pad_target_seqs.to(device)\n",
    "\n",
    "        classifier_hidden = classifier.init_hidden(batch_size, device)\n",
    "\n",
    "        # Encode input sequence\n",
    "        classifier_hidden = classifier(pad_input_seqs, input_seq_lengths, classifier_hidden)\n",
    "\n",
    "        #print(classifier_hidden.size(),pad_target_seqs.size())\n",
    "        loss = criterion(classifier_hidden.view(batch_size,2), pad_target_seqs)\n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        classifier_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i % print_every) == (print_every-1) or i == (len(trainloader) // trainloader.batch_size):\n",
    "            print('[%d, %5d] loss: %.4f' % (epoch+1, i+1, running_loss/print_every))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if skip_training:\n",
    "            break\n",
    "    if skip_training:\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier loaded from classifier_model.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk, submit these files together with your notebook\n",
    "classifier_filename = 'classifier_model.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        torch.save(classifier.state_dict(), classifier_filename)\n",
    "        print('Model saved to %s' % (classifier_filename))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    classifier = Classifier(dictionary_size, hidden_size)\n",
    "    classifier.load_state_dict(torch.load(classifier_filename, map_location=lambda storage, loc: storage))\n",
    "    print('Classifier loaded from %s.' % classifier_filename)\n",
    "    classifier = classifier.to(device)\n",
    "    classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = getLoader(train=False,mini=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every_test = 20000\n",
    "def compute_accuracy(classifier, testloader):\n",
    "    classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for pad_input_seqs, input_seq_lengths, targets, _ in testloader:\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            \n",
    "            pad_input_seqs, targets = pad_input_seqs.to(device), targets.to(device)\n",
    "            \n",
    "            init_hidden = classifier.init_hidden(batch_size, device)\n",
    "            output = classifier(pad_input_seqs, input_seq_lengths, init_hidden)\n",
    "            \n",
    "            out_flat = output.detach().numpy().argmax(axis=2)\n",
    "            predicted = torch.tensor(out_flat)\n",
    "            #print(\"pred\", predicted)\n",
    "            #print(\"true\", targets)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            #print(\"tot\",total)\n",
    "            #print(\"cor\",correct)\n",
    "            if (total % print_every_test == 0):\n",
    "                print(\"Counted:\",total,\"accuracy\",correct / total)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted: 20000 accuracy 0.831\n",
      "Counted: 40000 accuracy 0.82795\n",
      "Counted: 60000 accuracy 0.8256\n",
      "Counted: 80000 accuracy 0.82655\n",
      "Counted: 100000 accuracy 0.82632\n",
      "Counted: 120000 accuracy 0.8268416666666667\n",
      "Counted: 140000 accuracy 0.8270357142857143\n",
      "Counted: 160000 accuracy 0.8275625\n",
      "Counted: 180000 accuracy 0.8276388888888889\n",
      "Counted: 200000 accuracy 0.827915\n",
      "Counted: 220000 accuracy 0.8279909090909091\n",
      "Counted: 240000 accuracy 0.827875\n",
      "Counted: 260000 accuracy 0.8280961538461539\n",
      "Counted: 280000 accuracy 0.8280571428571428\n",
      "Counted: 300000 accuracy 0.8277633333333333\n",
      "Counted: 320000 accuracy 0.827578125\n",
      "0.827578125\n"
     ]
    }
   ],
   "source": [
    "print(\"Final accuracy:\",compute_accuracy(classifier,testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "slackloader = getLoader(train=False,mini=False, slack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_csv(\"data/words.csv\",squeeze=True)\n",
    "index_word = {x:y for x,y in enumerate(word_df[\"0\"])}\n",
    "word_index = {y:x for x,y in enumerate(word_df[\"0\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every_slack = 20\n",
    "def evaluate_slack(classifier, testloader):\n",
    "    classifier.eval()\n",
    "    negative = 0\n",
    "    positive = 0\n",
    "    total = 0\n",
    "    max_pos = 0\n",
    "    max_pos_idx = None\n",
    "    max_neg = 0\n",
    "    max_neg_idx = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (pad_input_seqs, input_seq_lengths, targets , _) in enumerate(testloader):\n",
    "            batch_size = pad_input_seqs.size(1)\n",
    "            \n",
    "            pad_input_seqs = pad_input_seqs.to(device)\n",
    "            \n",
    "            init_hidden = classifier.init_hidden(batch_size, device)\n",
    "            output = classifier(pad_input_seqs, input_seq_lengths, init_hidden)\n",
    "            \n",
    "            out_flat = output.detach().numpy().argmax(axis=2)\n",
    "            predicted = torch.tensor(out_flat)\n",
    "            \n",
    "            #print(i, \"both\",output.numpy().flatten())\n",
    "            \n",
    "            #print(\"ind pos\",output.numpy().flatten()[1])\n",
    "            #print(\"ind neg\",output.numpy().flatten()[0])\n",
    "            \n",
    "            if (max_pos < output.numpy().flatten()[1]):\n",
    "                max_pos = output.numpy().flatten()[1]\n",
    "                max_pos_idx = i\n",
    "            \n",
    "            if (max_neg < output.numpy().flatten()[0]):\n",
    "                max_neg = output.numpy().flatten()[0]\n",
    "                max_neg_idx = i\n",
    "\n",
    "            #print(\"sent\", pad_input_seqs)\n",
    "            #print(output)\n",
    "            #print(\"pred\", predicted)\n",
    "            #print(\"true\", targets)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            positive += (predicted == 1).sum().item()\n",
    "            negative += (predicted == 0).sum().item()\n",
    "            #print(\"pos\",positive)\n",
    "            #print(\"neg\",negative)\n",
    "\n",
    "            if (total % print_every_slack == 0):\n",
    "                print(\"Counted:\",total,\"positive\",positive / total,\"negative\",negative / total)\n",
    "    return positive, negative, total, max_pos_idx, max_neg_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted: 20 positive 0.6 negative 0.4\n",
      "Counted: 40 positive 0.65 negative 0.35\n",
      "Counted: 60 positive 0.5833333333333334 negative 0.4166666666666667\n",
      "Counted: 80 positive 0.5625 negative 0.4375\n",
      "Counted: 100 positive 0.56 negative 0.44\n",
      "Counted: 120 positive 0.5583333333333333 negative 0.44166666666666665\n",
      "Counted: 140 positive 0.55 negative 0.45\n",
      "Counted: 160 positive 0.55 negative 0.45\n",
      "Counted: 180 positive 0.5444444444444444 negative 0.45555555555555555\n",
      "Counted: 200 positive 0.555 negative 0.445\n",
      "Counted: 220 positive 0.5272727272727272 negative 0.4727272727272727\n",
      "Counted: 240 positive 0.5291666666666667 negative 0.4708333333333333\n",
      "Counted: 260 positive 0.5269230769230769 negative 0.47307692307692306\n",
      "Counted: 280 positive 0.5321428571428571 negative 0.46785714285714286\n",
      "Counted: 300 positive 0.5333333333333333 negative 0.4666666666666667\n",
      "Counted: 320 positive 0.540625 negative 0.459375\n",
      "Counted: 340 positive 0.5411764705882353 negative 0.4588235294117647\n",
      "Counted: 360 positive 0.5444444444444444 negative 0.45555555555555555\n",
      "Counted: 380 positive 0.5421052631578948 negative 0.45789473684210524\n",
      "Counted: 400 positive 0.535 negative 0.465\n",
      "Counted: 420 positive 0.5428571428571428 negative 0.45714285714285713\n",
      "Counted: 440 positive 0.5409090909090909 negative 0.4590909090909091\n",
      "Counted: 460 positive 0.5347826086956522 negative 0.4652173913043478\n",
      "Counted: 480 positive 0.51875 negative 0.48125\n",
      "Counted: 500 positive 0.508 negative 0.492\n",
      "Counted: 520 positive 0.5019230769230769 negative 0.4980769230769231\n",
      "Counted: 540 positive 0.4925925925925926 negative 0.5074074074074074\n",
      "Counted: 560 positive 0.48928571428571427 negative 0.5107142857142857\n",
      "Counted: 580 positive 0.4879310344827586 negative 0.5120689655172413\n",
      "Counted: 600 positive 0.48833333333333334 negative 0.5116666666666667\n",
      "Counted: 620 positive 0.4870967741935484 negative 0.5129032258064516\n",
      "Counted: 640 positive 0.4890625 negative 0.5109375\n",
      "Counted: 660 positive 0.4863636363636364 negative 0.5136363636363637\n",
      "Counted: 680 positive 0.47941176470588237 negative 0.5205882352941177\n",
      "Counted: 700 positive 0.4857142857142857 negative 0.5142857142857142\n",
      "Counted: 720 positive 0.48055555555555557 negative 0.5194444444444445\n",
      "Counted: 740 positive 0.4810810810810811 negative 0.518918918918919\n",
      "Counted: 760 positive 0.4842105263157895 negative 0.5157894736842106\n",
      "Counted: 780 positive 0.4846153846153846 negative 0.5153846153846153\n",
      "Counted: 800 positive 0.48125 negative 0.51875\n",
      "Counted: 820 positive 0.48048780487804876 negative 0.5195121951219512\n",
      "Counted: 840 positive 0.4797619047619048 negative 0.5202380952380953\n",
      "Counted: 860 positive 0.49186046511627907 negative 0.5081395348837209\n",
      "Counted: 880 positive 0.49204545454545456 negative 0.5079545454545454\n",
      "Counted: 900 positive 0.4911111111111111 negative 0.5088888888888888\n",
      "Counted: 920 positive 0.48478260869565215 negative 0.5152173913043478\n",
      "Counted: 940 positive 0.4797872340425532 negative 0.5202127659574468\n",
      "Counted: 960 positive 0.484375 negative 0.515625\n",
      "Counted: 980 positive 0.48673469387755103 negative 0.513265306122449\n",
      "Counted: 1000 positive 0.484 negative 0.516\n",
      "Counted: 1020 positive 0.48137254901960785 negative 0.5186274509803922\n",
      "Counted: 1040 positive 0.48365384615384616 negative 0.5163461538461539\n",
      "Counted: 1060 positive 0.47830188679245284 negative 0.5216981132075472\n",
      "Counted: 1080 positive 0.4787037037037037 negative 0.5212962962962963\n",
      "Counted: 1100 positive 0.48545454545454547 negative 0.5145454545454545\n",
      "Counted: 1120 positive 0.4928571428571429 negative 0.5071428571428571\n",
      "Counted: 1140 positive 0.493859649122807 negative 0.506140350877193\n",
      "Counted: 1160 positive 0.49224137931034484 negative 0.5077586206896552\n",
      "Counted: 1180 positive 0.488135593220339 negative 0.511864406779661\n",
      "Counted: 1200 positive 0.4875 negative 0.5125\n",
      "Counted: 1220 positive 0.4901639344262295 negative 0.5098360655737705\n",
      "Counted: 1240 positive 0.48951612903225805 negative 0.510483870967742\n",
      "Counted: 1260 positive 0.49047619047619045 negative 0.5095238095238095\n",
      "Counted: 1280 positive 0.48671875 negative 0.51328125\n",
      "Counted: 1300 positive 0.48538461538461536 negative 0.5146153846153846\n",
      "Counted: 1320 positive 0.48333333333333334 negative 0.5166666666666667\n",
      "Counted: 1340 positive 0.48656716417910445 negative 0.5134328358208955\n",
      "Counted: 1360 positive 0.4933823529411765 negative 0.5066176470588235\n",
      "Counted: 1380 positive 0.4971014492753623 negative 0.5028985507246376\n",
      "Counted: 1400 positive 0.4992857142857143 negative 0.5007142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(703, 706, 1409, 1022, 131)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_slack(classifier,slackloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set the channel purpose for finding project partners "
     ]
    }
   ],
   "source": [
    "for i,sent in enumerate(slackloader):\n",
    "    if (i == 1022):\n",
    "        for word in sent[0].numpy().flatten():\n",
    "            if (word != 2 and word != 3 and word != 0):\n",
    "                print(index_word[word],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are there any tutorial sessions this week ? the booking option is not available on CTX edited "
     ]
    }
   ],
   "source": [
    "for i,sent in enumerate(slackloader):\n",
    "    if (i == 131):\n",
    "        for word in sent[0].numpy().flatten():\n",
    "            if (word != 2 and word != 3 and word != 0):\n",
    "                print(index_word[word],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
